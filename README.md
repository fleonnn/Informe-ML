# An√°lisis Predictivo en Counter-Strike: Global Offensive (CS:GO)

---

Este proyecto de Machine Learning se enfoca en el an√°lisis y modelado predictivo de datos de partidas de Counter-Strike: Global Offensive (CS:GO). Nuestro objetivo principal es predecir el resultado de las rondas (`RoundWinner`) para contribuir al balanceo del juego, utilizando un dataset de m√°s de 7000 partidas.

---

## üéÆ Contexto del Negocio

Valve, la compa√±√≠a desarrolladora de CS:GO, nos contact√≥ como equipo de an√°lisis de datos y modelado de Machine Learning para explorar y crear modelos predictivos a partir de datos del juego.

En CS:GO, dos equipos de cinco jugadores, Terroristas (T) y Contra-Terroristas (CT), se enfrentan en cada partida. El objetivo de los Terroristas es plantar una bomba en uno de los sitios espec√≠ficos del mapa y defenderla hasta que explote. Los Contra-Terroristas, por su parte, deben evitar que la bomba sea plantada o desactivarla si ya ha sido colocada.

Los datos utilizados provienen de m√°s de 7000 partidas, con un m√°ximo de 10 jugadores por partida. Estos datos fueron extra√≠dos de "replays", archivos propietarios que contienen informaci√≥n detallada de cada acci√≥n de los jugadores. Se pre-procesaron y se consolidaron en un archivo CSV con 79.157 filas, donde cada fila representa a un jugador dentro de una partida, y 29 columnas que describen sus acciones.

### üéØ Objetivo del Proyecto

El objetivo principal es **predecir el ganador de la ronda (`RoundWinner`)** bas√°ndose en las din√°micas de juego, buscando un equilibrio en el juego y proporcionando insights valiosos.

### üí° Hip√≥tesis Consideradas

Durante la fase de **Business Understanding**, planteamos varias hip√≥tesis para guiar nuestro an√°lisis y modelado:

* **Hip√≥tesis 1: M√°s kills = mayor probabilidad de ganar.** Se postula que eliminar a los oponentes de manera efectiva aumenta las probabilidades de victoria al controlar el mapa y asegurar los objetivos.
* **Hip√≥tesis 2: Mapas como `de_inferno` favorecen a los CTs.** Observaciones previas y la estructura de ciertos mapas sugieren una ventaja t√°ctica para los Contra-Terroristas debido a dise√±os defensivos clave.
* **Hip√≥tesis 3: Equipamiento costoso mejora la tasa de victorias.** Se espera que una mejor econom√≠a y acceso a equipamiento superior (rifles, chalecos, granadas) se traduzca directamente en un mayor `win rate`.

### üìä M√©tricas de √âxito (KPIs)

Para evaluar el √©xito de nuestros modelos, establecimos los siguientes KPIs:

* **Precisi√≥n del Modelo:** Aspiramos a que el modelo tenga una precisi√≥n superior al $70\%$ en sus predicciones.
* **Balance del Juego:** Que el modelo contribuya a un balance donde ambos equipos ganen entre el $45\%$ y el $55\%$ de las rondas, evitando desequilibrios significativos.
* **Correlaci√≥n:** Que variables como `RoundKills` y `RoundHeadshots` muestren una correlaci√≥n clara con el resultado de la ronda.

---

## üöÄ Nuestro Enfoque Paso a Paso

Para lograr nuestros objetivos, seguimos una metodolog√≠a estructurada, abarcando las fases clave del ciclo de vida de un proyecto de Machine Learning:

### 1. Entendimiento del Negocio (Business Understanding)

* Definici√≥n del problema de negocio y objetivos.
* Identificaci√≥n de contexto y datos relevantes.
* Formulaci√≥n de hip√≥tesis para modelos de regresi√≥n y clasificaci√≥n.
* Establecimiento de KPIs para evaluar el rendimiento.

### 2. Entendimiento de los Datos (Data Understanding)

* Identificaci√≥n de tipos de variables y atributos.
* Detecci√≥n y an√°lisis de valores nulos y `outliers`.
* Realizaci√≥n de an√°lisis estad√≠sticos b√°sicos.
* Creaci√≥n de matrices de correlaci√≥n para identificar patrones.
* Detecci√≥n de patrones y comportamientos en los datos.
* Ingenier√≠a de nuevas variables a partir del an√°lisis.

### 3. Preparaci√≥n de los Datos (Data Preparation)

* Transformaci√≥n de variables categ√≥ricas a num√©ricas (Encoding).
* Tratamiento de valores nulos.
* Manejo de `outliers`.
* Normalizaci√≥n o estandarizaci√≥n de datos (Escalamiento).

### 4. Modelado (Modeling)

Exploramos un amplio rango de modelos de Machine Learning, dividi√©ndolos en tareas de **regresi√≥n** y **clasificaci√≥n** para abordar diferentes aspectos de nuestras hip√≥tesis. Para cada modelo, realizamos:

* Selecci√≥n de variables (X/Y).
* Divisi√≥n de datos en conjuntos de entrenamiento y prueba (`Train/Test Split`).
* Ajuste de hiperpar√°metros.
* Aplicaci√≥n de modelos y generaci√≥n de predicciones.
* Obtenci√≥n de m√©tricas de rendimiento.

**Modelos de Regresi√≥n Explorados:**

* Regresi√≥n Lineal
* Support Vector Regression (SVR)
* Decision Tree Regressor
* Random Forest Regressor
* KNN Regressor

**Modelos de Clasificaci√≥n Explorados:**

* Regresi√≥n Log√≠stica
* Support Vector Classification (SVC)
* √Årbol de Clasificaci√≥n
* Random Forest Classifier
* KNN Classifier

*Nota: Tambi√©n se consider√≥ la posibilidad de Modelos de Clustering, aunque el enfoque principal fue en regresi√≥n y clasificaci√≥n dadas las hip√≥tesis planteadas.*

### 5. Evaluaci√≥n (Evaluation)

En esta fase, analizamos las m√©tricas obtenidas de cada modelo y cada hip√≥tesis:

* **M√©tricas Clave:** Matriz de Confusi√≥n, $R^2$, RMSE, entre otras.
* An√°lisis detallado de cada hip√≥tesis para modelos de regresi√≥n y clasificaci√≥n.
* Identificaci√≥n de oportunidades de mejora en el pre-procesamiento o en los modelos.

### 6. Despliegue (Deployment)

Una vez seleccionados los modelos con mejor rendimiento y justificaci√≥n, se preparan para un posible despliegue.

* **Modelo de Regresi√≥n Final:** Regresi√≥n Lineal (para Hip√≥tesis 1)
* **Modelo de Clasificaci√≥n Final:** Random Forest Classifier (RFC) (para Hip√≥tesis 2)

---

## üõ†Ô∏è Justificaci√≥n de Modelos Finales

Tras un exhaustivo proceso de modelado y evaluaci√≥n, seleccionamos los siguientes modelos como los m√°s adecuados para abordar nuestras hip√≥tesis, bas√°ndonos en su rendimiento y la interpretaci√≥n de sus resultados:

### **Modelo de Regresi√≥n: Regresi√≥n Lineal (Hip√≥tesis 1)**

Nuestra Hip√≥tesis 1 buscaba determinar si "m√°s kills es igual a m√°s probabilidad de ganar". Aunque la hip√≥tesis original se centraba en la victoria general, el an√°lisis profundo nos llev√≥ a enfocar el modelo de regresi√≥n en predecir `MatchKills` bas√°ndose en otras m√©tricas de rendimiento individual como `MatchAssists` y `MatchHeadshots`.

Tras evaluar a fondo los cinco algoritmos distintos en nuestro dataset de CS:GO, llegamos a la conclusi√≥n contundente de que la **Regresi√≥n Lineal es el modelo que mejor predice `MatchKills`**, dado que ostenta el $R^2$ m√°s elevado, un $0.754$.

**¬øPor qu√© la Regresi√≥n Lineal result√≥ ser el mejor modelo?**

La Regresi√≥n Lineal mostr√≥ una habilidad sobresaliente para plasmar las relaciones no lineales complejas que son propias del gameplay en CS:GO. A diferencia de Random Forest, que asume relaciones directamente proporcionales, la Regresi√≥n Lineal puede modelar patrones m√°s sofisticados entre nuestras variables predictoras (`MatchAssists`, `MatchHeadshots`) y `MatchKills`. En Counter-Strike, la din√°mica del juego es intr√≠nsecamente intrincada. Un jugador con muchas asistencias no siempre tendr√° kills proporcionales, ya que esto depende del rol del jugador (support vs entry fragger), la coordinaci√≥n del equipo y las situaciones t√°cticas espec√≠ficas.

**An√°lisis Comparativo del Rendimiento de Modelos de Regresi√≥n:**

* **Regresi√≥n Lineal:** $R^2 = 0.754$ - El ganador indiscutible. Adem√°s, al considerar la relaci√≥n `Headshots` vs `Kills`, mostr√≥ un $R^2=0.72$ y $MSE=3.1$, confirmando que los headshots son un buen predictor de kills, aunque con errores en valores extremos (m√°s de 30 kills).
* **Random Forest:** $R^2 = 0.752$ - Buen rendimiento, pero un poco inferior.
* **Decision Tree:** $R^2 = 0.749$ - Propenso al overfitting. En el caso de `Headshots`, obtuvo un $R^2=0.73$ pero con alta varianza en predicciones extremas, sugiriendo que necesita mayor profundidad para capturar patrones complejos.
* **SVM:** $R^2 = 0.744$ - Sensible a los valores at√≠picos. Al evaluar `Equipamiento` vs `Kills` con SVR, se obtuvo un bajo desempe√±o ($R^2=0.0046$), demostrando que el valor del equipamiento no influye significativamente en las kills obtenidas.
* **KNN:** $R^2 = 0.726$ - El m√°s bajo, tambi√©n sensible a los valores at√≠picos.

**Interpretaci√≥n Pr√°ctica de los Resultados:**

El $R^2$ de $0.754$ implica que nuestro modelo de Regresi√≥n Lineal explica aproximadamente el $75.4\%$ de la variabilidad en las eliminaciones de una partida. Esto es extraordinariamente s√≥lido, sobre todo teniendo en cuenta la naturaleza intr√≠nsecamente impredecible de CS:GO, donde factores como el timing perfecto, decisiones en fracciones de segundo y elementos de azar tambi√©n influyen de forma importante.

**Robustez del Modelo:**

Con este modelo, podemos predecir con aproximadamente un $75\%$ de certeza cu√°ntas eliminaciones obtendr√° un jugador bas√°ndonos en sus asistencias esperadas, precisi√≥n de headshots y el valor del equipamiento inicial de su equipo. Esto tiene aplicaciones valiosas para an√°lisis t√°ctico, coaching y estrategias de equipo.

### **Modelo de Clasificaci√≥n: Random Forest Classifier (Hip√≥tesis 2)**

Nuestra Hip√≥tesis 2 planteaba que "Mapas como `de_inferno` favorecen a los CTs". Sin embargo, durante el proceso de modelado, la exploraci√≥n m√°s profunda nos llev√≥ a enfocar el modelo de clasificaci√≥n en **predecir la supervivencia (`Survived`)** bas√°ndose en el `TeamStartingEquipmentValue`, que es una variable crucial para las decisiones t√°cticas del juego.

Despu√©s de evaluar minuciosamente los cinco algoritmos de clasificaci√≥n para predecir la supervivencia en CS:GO bas√°ndose en el valor de equipamiento inicial del equipo (`TeamStartingEquipmentValue`), podemos determinar que **Random Forest Classifier es el modelo superior, obteniendo la Accuracy m√°s alta de $60.14\%$**.

**¬øPor qu√© Random Forest result√≥ ser el mejor modelo?**

Random Forest demostr√≥ ser el algoritmo m√°s robusto para este problema de clasificaci√≥n binaria tan desafiante. La supervivencia en CS:GO es inherentemente compleja y depende de m√∫ltiples factores m√°s all√° del equipamiento inicial, pero Random Forest logr√≥ extraer los patrones m√°s significativos de esta √∫nica variable predictora. El modelo utiliz√≥ 50 √°rboles de decisi√≥n (`n_estimators=50`) con una profundidad m√°xima de 5 niveles, lo que le permiti√≥ capturar relaciones no lineales sin caer en overfitting. Esta configuraci√≥n optimizada mediante validaci√≥n cruzada demostr√≥ que el algoritmo puede balancear efectivamente entre bias y varianza, crucial cuando trabajamos con una sola caracter√≠stica predictora.

**An√°lisis Comparativo de Rendimiento de Modelos de Clasificaci√≥n:**

* **Random Forest:** Accuracy = $60.14\%$ - El claro ganador.
* **KNN (k=20):** Accuracy = $59.8\%$ - Muy cercano, pero ligeramente inferior.
* **Regresi√≥n Log√≠stica:** Accuracy = $59.08\%$ - S√≥lido pero limitado por su linearidad. Al predecir `Supervivencia`, obtuvo un Accuracy=$67\%$ ($F1=75\%$ para no-supervivientes, $52\%$ para supervivientes). Mejor√≥ con ajustes pero a√∫n tiene un `recall` bajo ($45\%$) para la clase positiva.
* **√Årbol de Clasificaci√≥n:** Accuracy = $55\%$ - Vulnerable al overfitting con una sola variable. Para predecir `Headshots`, obtuvo un Accuracy=$60\%$ pero fall√≥ totalmente en predecir supervivientes (`recall=0\%`), evidenciando que los headshots no son predictores suficientes por s√≠ solos para la supervivencia.
* **SVM (Kernel Lineal):** Accuracy = $62.6\%$ con un `recall` cr√≠ticamente bajo ($21.6\%$) para supervivientes, indicando que las variables usadas (flanqueo, equipamiento) no son determinantes por s√≠ solas. Requiri√≥ tiempos de entrenamiento significativamente mayores.

**Interpretaci√≥n Detallada de los Resultados:**

La accuracy de $60.14\%$ puede parecer modesta, pero es importante contextualizar este resultado. Estamos intentando predecir supervivencia usando √∫nicamente el valor de equipamiento inicial del equipo, lo cual es una tarea extremadamente desafiante. En CS:GO, la supervivencia depende de factores como habilidad individual, `positioning`, decisiones t√°cticas, `timing`, y hasta elementos de suerte que no est√°n capturados en esta variable.

**An√°lisis del Reporte de Clasificaci√≥n (Random Forest):**

* **Precision para "False" (No Sobrevivi√≥):** $0.61$ - El modelo identifica correctamente el $61\%$ de las muertes predichas.
* **Recall para "False":** $0.91$ - Captura el $91\%$ de todas las muertes reales, excelente sensibilidad.
* **F1-Score para "False":** $0.73$ - Balance s√≥lido entre precision y recall.
* **Precision para "True" (Sobrevivi√≥):** $0.52$ - M√°s desafiante predecir supervivencia.
* **Recall para "True":** $0.15$ - Solo captura el $15\%$ de las supervivencias reales.

**Hallazgos Clave Adicionales:**

* Las habilidades individuales (`headshots`) predicen mejor el rendimiento (`kills`) que factores de equipamiento.
* Ning√∫n modelo actual predice efectivamente la supervivencia (todos tienen `recall` < $50\%$ para esta clase).
* El desbalance de clases afecta significativamente los modelos de clasificaci√≥n.

**Qu√© nos dice esto sobre el comportamiento del modelo:**

El modelo es significativamente mejor prediciendo muertes que supervivencias. Esto tiene sentido l√≥gico: equipos con menor valor de equipamiento inicial tienden a tener mayores probabilidades de muerte, una relaci√≥n m√°s directa y predecible. La supervivencia, por otro lado, puede ocurrir incluso con equipamiento b√°sico debido a factores externos no capturados.

**Robustez y Optimizaci√≥n:**

El `split` √≥ptimo de $0.3$ ($30\%$ para `testing`) asegur√≥ suficientes datos para entrenamiento mientras manten√≠a una evaluaci√≥n robusta. Los hiperpar√°metros optimizados (`max_depth=5`, `criterion='gini'`) previenen el `overfitting`, crucial cuando trabajamos con datasets de CS:GO que pueden tener patrones complejos.

**Implicaciones Pr√°cticas:**

Con este modelo, los equipos pueden estimar con aproximadamente $60\%$ de precisi√≥n las probabilidades de supervivencia bas√°ndose en su inversi√≥n inicial en equipamiento. Esto es valioso para decisiones econ√≥micas estrat√©gicas: ¬øvale la pena hacer "force-buy" o es mejor una "eco round"?

A continuaci√≥n, se muestran los gr√°ficos que respaldan visualmente estos hallazgos y demuestran la superioridad del modelo Random Forest para esta tarea de clasificaci√≥n.

*(Aqu√≠ puedes insertar la tabla resumen de las 3 hip√≥tesis de clasificaci√≥n si la tienes en formato imagen o texto.)*

---
